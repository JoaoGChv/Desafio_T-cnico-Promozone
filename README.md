# Promozone Promotion Collector

Coletor autom√°tico de promo√ß√µes do Mercado Livre com deduplica√ß√£o inteligente e deploy no GCP Cloud Run.

## üéØ Vis√£o Geral

**Promozone** √© um servi√ßo serverless (Flask + Cloud Run) que:

- ‚úÖ Coleta promo√ß√µes de 3 fontes do Mercado Livre
- ‚úÖ Normaliza e valida dados em tempo real
- ‚úÖ Realiza deduplica√ß√£o via MERGE SQL no BigQuery
- ‚úÖ Registra logs operacionais detalhados
- ‚úÖ Fornece API REST para consultas e monitoramento

### Pipeline de Dados

```
API Trigger (/collect)
    ‚Üì
Scraper (httpx + BeautifulSoup4)
    ‚Üì
Normalizer (valida√ß√£o e enriquecimento)
    ‚Üì
BigQuery MERGE (deduplica√ß√£o autom√°tica)
    ‚Üì
Execution Logs (rastreamento completo)
```

---

## üìã Arquitetura e Stack

### Tecnologias

| Componente | Tecnologia |
|-----------|-----------|
| Framework Web | Flask 3.0 |
| HTTP Client | httpx (async) |
| Parser HTML | BeautifulSoup4 + lxml |
| Database | Google BigQuery |
| Container | Docker (python:3.11-slim) |
| Deploy | Cloud Run (GCP) |
| Logging | JSON estruturado |

### Estrutura do Projeto

```
/Desafio-Promozone
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py              # Configura√ß√µes centralizadas
‚îÇ   ‚îú‚îÄ‚îÄ main.py                # Aplica√ß√£o Flask principal
‚îÇ   ‚îú‚îÄ‚îÄ scrapers/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py            # Scraper base com retry
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mercadolivre.py    # Implementa√ß√£o espec√≠fica
‚îÇ   ‚îú‚îÄ‚îÄ normalizers/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ promotion_normalizer.py  # Normaliza√ß√£o de dados
‚îÇ   ‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ bigquery_client.py  # Cliente BigQuery com MERGE
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ logger.py          # Logging estruturado
‚îÇ       ‚îú‚îÄ‚îÄ normalizers.py     # Fun√ß√µes de normaliza√ß√£o
‚îÇ       ‚îî‚îÄ‚îÄ retry.py           # Retry com exponential backoff
‚îú‚îÄ‚îÄ infra/
‚îÇ   ‚îú‚îÄ‚îÄ create_tables.py       # Script para setup BigQuery
‚îÇ   ‚îú‚îÄ‚îÄ deploy.sh              # Deploy autom√°tico Cloud Run
‚îÇ   ‚îî‚îÄ‚îÄ setup_local.sh         # Setup local
‚îú‚îÄ‚îÄ Dockerfile                 # Imagem para Cloud Run
‚îú‚îÄ‚îÄ requirements.txt           # Depend√™ncias Python
‚îú‚îÄ‚îÄ .env.example              # Template de vari√°veis
‚îî‚îÄ‚îÄ README.md                 # Este arquivo
```

---

## üöÄ Quickstart

### 1Ô∏è‚É£ Local Setup

```bash
# Clone ou extraia o projeto
cd Desafio-Promozone

# Setup local
bash infra/setup_local.sh

# Ative o virtual environment
source venv/bin/activate

# Configure credenciais GCP
export GOOGLE_APPLICATION_CREDENTIALS=/caminho/para/key.json

# Atualize .env com seu PROJECT_ID
# GCP_PROJECT_ID=seu-projeto-gcp
```

### 2Ô∏è‚É£ Criar Tabelas no BigQuery

```bash
# Cria dataset e tabelas automaticamente
python infra/create_tables.py seu-projeto-gcp promozone
```

### 3Ô∏è‚É£ Executar Localmente

```bash
# Instale gunicorn para servidor production-like
pip install gunicorn

# Inicie a aplica√ß√£o
python -m app.main

# Ou com gunicorn
gunicorn --bind 0.0.0.0:8080 --workers 4 "app.main:create_app()"
```

A API estar√° dispon√≠vel em `http://localhost:8080`

### 4Ô∏è‚É£ Testar Endpoints

```bash
# Health check
curl http://localhost:8080/health

# Iniciar coleta (POST)
curl -X POST http://localhost:8080/collect

# Ver estat√≠sticas (√∫ltimas 24h)
curl http://localhost:8080/stats
```

---

## üê≥ Docker e Cloud Run

### Build Local

```bash
docker build -t promozone-collector .
docker run -p 8080:8080 \
  -e GCP_PROJECT_ID=seu-projeto \
  -e GOOGLE_APPLICATION_CREDENTIALS=/app/secrets/gcp-key.json \
  -v /caminho/para/key.json:/app/secrets/gcp-key.json:ro \
  promozone-collector
```

### Deploy no Cloud Run

```bash
# Execute o script de deploy
bash infra/deploy.sh seu-projeto-gcp

# Ou manualmente:
gcloud run deploy promozone-collector \
  --image gcr.io/seu-projeto-gcp/promozone-collector:latest \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --memory 1Gi \
  --cpu 2 \
  --timeout 120
```

---

## üìä Endpoints da API

### `GET /health`

Health check simples.

**Response:**
```json
{
  "status": "healthy"
}
```

---

### `POST /collect`

Inicia ciclo completo de coleta e persist√™ncia.

**Response:**
```json
{
  "execution_id": "uuid-da-execu√ß√£o",
  "status": "success",
  "items_collected": 75,
  "items_normalized": 75,
  "items_inserted": 68,
  "items_deduplicated": 7,
  "duration_seconds": 23.45,
  "start_time": "2026-02-09T10:15:30.123456",
  "end_time": "2026-02-09T10:15:53.573456"
}
```

---

### `GET /stats`

Retorna estat√≠sticas das √∫ltimas 24 horas.

**Response:**
```json
{
  "executions": 3,
  "total_items": 156,
  "unique_items": 142,
  "by_source": {
    "daily_offers": 52,
    "technology": 48,
    "electronics": 56
  },
  "avg_discount_percent": 18.5
}
```

---

## üîê Seguran√ßa e Vari√°veis de Ambiente

**NUNCA** fa√ßa hardcode de credenciais. Use vari√°veis de ambiente:

```bash
export GCP_PROJECT_ID=seu-projeto
export GOOGLE_APPLICATION_CREDENTIALS=/caminho/para/key.json
export BIGQUERY_DATASET=promozone
export REQUEST_TIMEOUT=30
export MAX_RETRIES=3
```

Para Cloud Run, use **Secret Manager**:

```bash
gcloud secrets create gcp-key --data-file=/caminho/para/key.json

gcloud run deploy promozone-collector \
  --update-secrets GOOGLE_APPLICATION_CREDENTIALS=gcp-key:latest
```

---

## üìà Schema BigQuery

### Tabela: `promotions`

| Campo | Tipo | Descri√ß√£o |
|-------|------|-----------|
| `marketplace` | STRING | Nome do marketplace (ex: "mercadolivre") |
| `item_id` | STRING | ID √∫nico do produto (ex: "MLB123456789") |
| `url` | STRING | URL do produto |
| `title` | STRING | T√≠tulo/nome do produto |
| `price` | NUMERIC | Pre√ßo atual em BRL |
| `original_price` | NUMERIC | Pre√ßo original (nullable) |
| `discount_percent` | FLOAT64 | Percentual de desconto (nullable) |
| `seller` | STRING | Nome do vendedor |
| `image_url` | STRING | URL da imagem do produto |
| `source` | STRING | Fonte da coleta (daily_offers, technology, electronics) |
| `dedupe_key` | STRING | Chave de deduplica√ß√£o (marketplace#item_id#price) |
| `execution_id` | STRING | ID da execu√ß√£o que coletou |
| `collected_at` | TIMESTAMP | Momento da coleta |
| `inserted_at` | TIMESTAMP | Momento da inser√ß√£o no BigQuery |

**√çndices de Clustering:** `dedupe_key`, `execution_id`

---

### Tabela: `execution_logs`

| Campo | Tipo | Descri√ß√£o |
|-------|------|-----------|
| `execution_id` | STRING | ID √∫nico da execu√ß√£o |
| `start_time` | TIMESTAMP | Hora de in√≠cio |
| `end_time` | TIMESTAMP | Hora de t√©rmino |
| `items_collected` | INTEGER | Total de itens coletados |
| `items_inserted` | INTEGER | Total de itens inseridos (novos) |
| `items_deduplicated` | INTEGER | Total de itens duplicados |
| `status` | STRING | Status (success/error) |
| `error_message` | STRING | Mensagem de erro se houver (nullable) |

---

## üîç Queries SQL √öteis

### √öltimas Coletas (√∫ltimas 24h)

```sql
SELECT
  execution_id,
  start_time,
  end_time,
  items_collected,
  items_inserted,
  items_deduplicated,
  status
FROM `seu-projeto.promozone.execution_logs`
WHERE start_time >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 24 HOUR)
ORDER BY start_time DESC
LIMIT 10;
```

### Produtos Mais Descontados

```sql
SELECT
  title,
  seller,
  price,
  original_price,
  discount_percent,
  source,
  collected_at
FROM `seu-projeto.promozone.promotions`
WHERE collected_at >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 24 HOUR)
ORDER BY discount_percent DESC
LIMIT 20;
```

### Produtos Duplicados (√∫ltimas 24h)

```sql
SELECT
  dedupe_key,
  COUNT(*) as count,
  ARRAY_AGG(DISTINCT execution_id) as executions
FROM `seu-projeto.promozone.promotions`
WHERE collected_at >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 24 HOUR)
GROUP BY dedupe_key
HAVING COUNT(*) > 1
ORDER BY count DESC;
```

### Estat√≠sticas por Fonte

```sql
SELECT
  source,
  COUNT(*) as total_items,
  COUNT(DISTINCT item_id) as unique_items,
  AVG(price) as avg_price,
  AVG(discount_percent) as avg_discount,
  MIN(collected_at) as first_collection,
  MAX(collected_at) as last_collection
FROM `seu-projeto.promozone.promotions`
WHERE collected_at >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 24 HOUR)
GROUP BY source
ORDER BY total_items DESC;
```

---

## üß™ Testes

### Teste Local sem GCP

```bash
# Instale depend√™ncias de teste
pip install pytest pytest-asyncio

# Execute testes
pytest tests/
```

### Teste de Scraping

```bash
python -c "
import asyncio
from app.scrapers.mercadolivre import MercadoLivreScraper

async def test():
    scraper = MercadoLivreScraper()
    results = await scraper.scrape_all()
    for source, items in results.items():
        print(f'{source}: {len(items)} itens')

asyncio.run(test())
"
```

---

## üìù Checklist de Implementa√ß√£o

- [x] Arquitetura fim-a-fim (Scraper ‚Üí Normalizer ‚Üí BigQuery ‚Üí Logs)
- [x] Scraper com retry e exponential backoff
- [x] Normaliza√ß√£o de pre√ßos (R$ 1.250,50 ‚Üí 1250.50)
- [x] MERGE SQL com deduplica√ß√£o autom√°tica
- [x] API Flask com 3 endpoints (/health, /collect, /stats)
- [x] Logging estruturado em JSON
- [x] Dockerfile para Cloud Run
- [x] Vari√°veis de ambiente (sem hardcode)
- [x] Setup scripts (local e cloud)
- [x] Documenta√ß√£o completa
- [x] Queries SQL de valida√ß√£o

---

## üìö Refer√™ncias

- [Google Cloud BigQuery Documentation](https://cloud.google.com/bigquery/docs)
- [Cloud Run Quickstart](https://cloud.google.com/run/docs/quickstarts/build-and-deploy)
- [Flask Documentation](https://flask.palletsprojects.com/)
- [httpx Async Client](https://www.python-httpx.org/)
- [BeautifulSoup4 Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)

---

## üêõ Troubleshooting

### Erro: "Permission denied" no BigQuery

```bash
# Verifique credenciais GCP
gcloud auth list
gcloud config list

# Redefina credenciais
export GOOGLE_APPLICATION_CREDENTIALS=/caminho/correto/key.json
```

### Scraper n√£o coleta itens

- Verifique os seletores CSS em `app/scrapers/mercadolivre.py`
- O Mercado Livre pode ter alterado a estrutura HTML
- Aumente `REQUEST_TIMEOUT` se o site for lento

### Erro: "Table not found" no BigQuery

```bash
# Recrie as tabelas
python infra/create_tables.py seu-projeto-gcp
```

---

```python
import os

# Let's check what files are available in the current directory to be sure of the naming convention
for root, dirs, files in os.walk('.'):
    for file in files:
        if file.endswith('.md') or file.endswith('.pdf'):
            print(os.path.join(root, file))


```

```text
Code executed successfully!

```

> ### **‚öñÔ∏è Trade-offs e Decis√µes**
> 
> 
> * **Cria√ß√£o de Tabelas:** Devido a atrasos na propaga√ß√£o de pol√≠ticas de IAM do GCP para cria√ß√£o din√¢mica de objetos via SDK em tempo de execu√ß√£o, optei pela cria√ß√£o manual do schema via Console SQL para garantir a estabilidade do pipeline de dados dentro do prazo.
> * **Abordagem de Scraping:** Utilizei `httpx` e `BeautifulSoup4` em vez de ferramentas mais pesadas (como Selenium) para otimizar o consumo de mem√≥ria e CPU no Cloud Run, garantindo uma execu√ß√£o mais barata e r√°pida.
> * **Deduplica√ß√£o no Banco:** A escolha de fazer o dedupe via `MERGE` diretamente no BigQuery (em vez de em mem√≥ria) foi feita para garantir a consist√™ncia dos dados mesmo em execu√ß√µes paralelas.

